Number: 1155Date: 20-May-84 11':44':20Submitter: LE.PASASource:  kipps@RAND-UNIX.ARPASubject: HPRINT breaks on large datastructures (over 32K pointers)Assigned To: Attn: MasinterStatus: OpenIn/By: Problem Type: Design - ImplImpact: ModerateDifficulty: HardFrequency: EverytimePriority: PerhapsSystem: Language SupportSubsystem: Read and PrintMachine: Disk: Lisp Version:  Fugue 6Source Files: Microcode Version: Memory Size: File Server: Server Software Version: Disposition: '["masinter.PA" "13-Sep-84 13':59':20" Attn':]Description: ' I''m trying to put a large circular data structure out to disk'and am having some problems.  I''m doing this via MAKEFILE.'The variable which points to the circular data structure'has the filecom property, HORRIBLEVARS.  When I do the MAKEFILE,'it breaks at HARRAY (during HPRINT) with the message''ILLEGAL ARG'32768''The LEN passed to HARRAY = 24575.  What''s the problem?''			Jim K.''-----''Date': 14 May 84 17':36 PDT'From': Masinter.pa'Subject': Re': Bug report, HPRINT'In-reply-to': kipps@RAND-UNIX.ARPA''s message of Mon, 14 May 84 13':17 PDT'To': kipps@RAND-UNIX'cc': Masinter.pa, Henry@RAND-UNIX, marti@RAND-UNIX, guyton@RAND-UNIX, obrien@RAND-UNIX, vanMelle.pa'cc': 1100Support'reply-to': 1100Support.pasa, Masinter.PA''There is a problem with dumping out datastructures with more than 32K pointers in them in the current implementation of HPRINT. If you really INTENDED this to work, we''ll have to rethink how we implement HPRINT (or hash arrays for that matter). ''Does your datastructure really have 32K pointers in it?'---------''Date': 18 May 84 11':37 PDT'From': masinter.pa'Subject': Re': Bug report, HPRINT'In-reply-to': Kiewiet.pasa''s message of 18 May 84 10':24 PDT'To': Kiewiet.pasa'cc': 1100Support.pasa, Masinter.PA''no, please submit AR -- holding off submitting it is a recipe for letting it drop on the floor. When you get a response, it can be used to modify the old AR...''Does that seem reasonable?''Date':  7 Jun 84 16':55 PDT'From': Kaplan.pa'Subject': Re': AR#1155, making huge hash arrays'In-reply-to': Masinter.PA''s message of 7 Jun 84 16':13':50 PDT (Thursday)'To': Masinter.PA'cc': jellinek.PA, kaplan.PA''Hasharrays would be doubled in size if we upped the array allocator to work in quad-word chunks, even more than that if we did some sensitivity experiments on the load factor.''Otherwise, a bucket scheme could easily be implemented to give unlimited hash arrays.  But somebody ought to do some sort of analysis on working set, performance expectations, when to rehash, etc.''--Ron''Workaround: Test Case: Edit-By: masinter.PAEdit-Date: 13-Sep-84 13':59':22